{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#              Integração com a API do Sheets \n",
    "# =============================================================\n",
    "from googleapiclient.discovery import build    # Bibliotecas desenvolvidas pelo google \n",
    "from google.oauth2 import service_account\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keys_piperun.json', 'r') as file:\n",
    "    tokens = json.load(file)\n",
    "\n",
    "access_token_pipe = tokens['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "with open('keys_facebook.json', 'r') as file:\n",
    "    tokens = json.load(file)\n",
    "\n",
    "access_token = tokens['access_token']\n",
    "account_id = tokens['account_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oportunidades = \"\"\"26446836\n",
    "25111597\n",
    "26071781\n",
    "26474351\"\"\"\n",
    "\n",
    "oportunidades_n = oportunidades.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json \n",
    "import pandas as pd \n",
    "\n",
    "# URL da API do Piperun para obter as notas das oportunidades\n",
    "api_url_2 = \"https://api.pipe.run/v1/deals\"\n",
    "api_url = \"https://api.pipe.run/v1/notes\"\n",
    "\n",
    "# Configuração dos cabeçalhos\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"token\": access_token_pipe\n",
    "}\n",
    "\n",
    "# Parâmetros da solicitação\n",
    "params = {\n",
    "    \"deal_id\": \"26446836\"\n",
    "}\n",
    "\n",
    "# Faz a solicitação GET para a API do Piperun\n",
    "response2 = requests.get(api_url_2, headers=headers, params=params)\n",
    "# Faz a solicitação GET para a API do Piperun\n",
    "response = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "# Verifica o código de status da resposta\n",
    "if response2.status_code == 200:\n",
    "    # A solicitação foi bem-sucedida\n",
    "    notas_oportunidades = json.loads(response.text)['data']\n",
    "    df = pd.DataFrame(data=notas_oportunidades)\n",
    "    df = pd.DataFrame(data=notas_oportunidades)\n",
    "    # Faça o processamento necessário nas notas das oportunidades aqui\n",
    "else:\n",
    "    # Ocorreu um erro na solicitação\n",
    "    print(\"Erro na solicitação:\", response2.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26446836\n",
      "25111597\n",
      "26071781\n",
      "26474351\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# URL da API do Piperun para obter as notas das oportunidades\n",
    "api_url = \"https://api.pipe.run/v1/notes\"\n",
    "api_url_2 = \"https://api.pipe.run/v1/deals\"\n",
    "\n",
    "df_final = []\n",
    "\n",
    "for deal_id in oportunidades_n:\n",
    "\n",
    "    # Parâmetros da solicitação\n",
    "    params = {\n",
    "        \"deal_id\": deal_id\n",
    "    }\n",
    "\n",
    "    # Faz a solicitação GET para a API do Piperun\n",
    "    response2 = requests.get(api_url_2, headers=headers, params=params)\n",
    "    response = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "    # Verifica o código de status da resposta\n",
    "    if response.status_code == 200:\n",
    "        print(deal_id)\n",
    "        # A solicitação foi bem-sucedida\n",
    "        notas_oportunidades = json.loads(response.text)['data']\n",
    "        oportunidades = json.loads(response2.text)['data']\n",
    "        df = pd.DataFrame(data=notas_oportunidades)\n",
    "        df['title'] = oportunidades[0]['title']\n",
    "        df_final.append(df)\n",
    "        # Faça o processamento necessário nas notas das oportunidades aqui\n",
    "    else:\n",
    "        # Ocorreu um erro na solicitação\n",
    "        print(\"Erro na solicitação:\", response.status_code)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame final\n",
    "df_final = pd.concat(df_final, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empresa de cadastro: \n",
      "\n",
      "Exemplo de texto\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Coluna em formato HTML\n",
    "coluna_html = '<p>Empresa de cadastro:&nbsp;\\n\\n<!--StartFragment-->Exemplo de texto<!--EndFragment--></p>'\n",
    "\n",
    "# Converter HTML para texto\n",
    "soup = BeautifulSoup(coluna_html, 'html.parser')\n",
    "texto = soup.get_text()\n",
    "\n",
    "print(texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Função para converter HTML em texto\n",
    "def html_to_text(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    texto = soup.get_text()\n",
    "    return texto\n",
    "\n",
    "# Aplicar a conversão em toda a coluna 'text'\n",
    "df_final['text'] = df_final['text'].apply(lambda html: html_to_text(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keys_redshift.json', 'r') as file:\n",
    "    tokens = json.load(file)\n",
    "\n",
    "host = tokens['host']\n",
    "port = tokens['port']\n",
    "database = tokens['database']\n",
    "user = tokens['user']\n",
    "password = tokens['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Query SQL\n",
    "query = \"\"\"select * from piperun.deal_customfields dc \n",
    "where dc.customfields_id = 156930;\"\"\"\n",
    "\n",
    "# Conexão ao Redshift\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "\n",
    "# Criação de um cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execução da consulta\n",
    "cur.execute(query)\n",
    "\n",
    "# Recuperação dos resultados\n",
    "results = cur.fetchall()\n",
    "colunas = [desc[0] for desc in cur.description]\n",
    "\n",
    "# Fechamento do cursor e da conexão\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id_x', 'account_id', 'user_id', 'pipeline_id', 'stage_id', 'deal_id',\n",
      "       'company_id', 'person_id', 'call_id', 'user_name', 'text', 'created_at',\n",
      "       'updated_at_x', 'title', 'customfields_id', 'type', 'value', 'id_y',\n",
      "       'updated_at_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_redshift = pd.DataFrame(results, columns=colunas)\n",
    "\n",
    "# Juntar os DataFrames usando o campo \"deal_id\" como chave de junção\n",
    "df_merged = pd.merge(df_final, df_redshift, on='deal_id', how='left')\n",
    "\n",
    "# Imprimir o resultado final\n",
    "print(df_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_redshift Index(['deal_id', 'customfields_id', 'type', 'value', 'id', 'updated_at'], dtype='object') \n",
      "df_final Index(['id', 'account_id', 'user_id', 'pipeline_id', 'stage_id', 'deal_id',\n",
      "       'company_id', 'person_id', 'call_id', 'user_name', 'text', 'created_at',\n",
      "       'updated_at', 'title'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"df_redshift\",df_redshift.columns,\"\\ndf_final\", df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer um left join entre df_final e df_redshift usando o campo \"deal_id\" como chave de junção\n",
    "df_merged = pd.merge(df_final, df_redshift[['deal_id', 'value']], on='deal_id', how='left')\n",
    "\n",
    "# Imprimir o resultado final\n",
    "df_merged = df_merged.rename({'value': 'id_jira'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobe_tabela(id, pagina, df_merged):\n",
    "    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "    SERVICE_ACCOUNT_FILE = r\"keys_google.json\"  # Arquivo com as crednciais \n",
    "\n",
    "    creds = None\n",
    "    creds = service_account.Credentials.from_service_account_file(    # Função com a aplicação das credenciais \n",
    "            SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "\n",
    "    SAMPLE_SPREADSHEET_ID  = id # Pasta marketing_facebook\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "    # Call the Sheets API \n",
    "    sheet = service.spreadsheets()\n",
    "\n",
    "    sheet.values().clear(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=f\"{pagina}!A:K\").execute()\n",
    "    if \"creted_at\" in df_merged.columns:\n",
    "        histories = df_merged.sort_values(by=['created_at'])\n",
    "    histories = df_merged.sort_values(by=['deal_id'])\n",
    "    histories.fillna(\" \",inplace=True)\n",
    "    planilha_histories = [histories.columns.tolist()] + histories.values.tolist()\n",
    "\n",
    "    request = sheet.values().update(spreadsheetId=SAMPLE_SPREADSHEET_ID, \n",
    "                                    range=f\"{pagina}!A:O\",\n",
    "                                    valueInputOption=\"USER_ENTERED\",\n",
    "                                    body={\"values\": planilha_histories}).execute()\n",
    "    print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spreadsheetId': 'xxxxxxxxxxxxxxxxxxxxxxxxxx', 'updatedRange': 'notas_deals!A1:O12', 'updatedRows': 12, 'updatedColumns': 15, 'updatedCells': 180}\n"
     ]
    }
   ],
   "source": [
    "sobe_tabela(\"xxxxxxxxxxxxxxxxxxxxxxxxxx\",\"notas_deals\",df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'account_id', 'user_id', 'pipeline_id', 'stage_id', 'deal_id',\n",
       "       'company_id', 'person_id', 'call_id', 'user_name', 'text', 'created_at',\n",
       "       'updated_at', 'title', 'id_jira'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supondo que você já tenha um DataFrame chamado df com as colunas id_jira e text\n",
    "\n",
    "# Agrupar por id_jira e juntar os textos\n",
    "df_grouped = df_merged.groupby('deal_id')['text'].apply(' '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spreadsheetId': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'updatedRange': 'notas_deals_agrupada!A1:B5', 'updatedRows': 5, 'updatedColumns': 2, 'updatedCells': 10}\n"
     ]
    }
   ],
   "source": [
    "sobe_tabela(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\"notas_deals_agrupada\",df_grouped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketing_amb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
